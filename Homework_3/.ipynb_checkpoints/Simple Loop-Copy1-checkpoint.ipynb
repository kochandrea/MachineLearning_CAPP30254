{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Rayid Ghani's simple loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from LoadData import outcomes_df, projects_df, mega_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ClassifierLoopFunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-31971dbc3fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCleaningFunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExplorationFunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mClassifierLoopFunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclasf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoadData\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mVariables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ClassifierLoopFunctions'"
     ]
    }
   ],
   "source": [
    "import CleaningFunctions as cf\n",
    "import ExplorationFunctions as ef\n",
    "import ClassifierLoopFunctions as clasf\n",
    "import LoadData as ld\n",
    "from Variables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_from_projects = GEO_VARIABLES + ID_VARIABLES + IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_vars = [x for x in projects_df.columns if x not in remove_from_projects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_df = mega_df[keep_vars + TARGET_VARIABLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_list = list(projects_df.columns)\n",
    "# p_list = p_list[6:] #remove columns dealing with IDs and latlong\n",
    "# keep_cols = list(p_list) + ['fully_funded']\n",
    "# labeled_df = mega_df[keep_cols] #dataframe of projects info with funding info\n",
    "# labeled_df = cf.dummytize(labeled_df)\n",
    "# labeled_df = cf.impute_mean(labeled_df, given_cols=TO_BE_DISCRETIZED_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.has_na(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dum_variables_of_interest = [\n",
    "'poverty_level', \n",
    "'teacher_prefix',\n",
    "'primary_focus_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = cf.change_to_1_0(labeled_df)\n",
    "labeled_df = cf.impute_mean(labeled_df, given_cols=TO_BE_DISCRETIZED_VARIABLES)\n",
    "labeled_df = cf.dummytize(labeled_df, dum_variables_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['school_nlns', 'school_kipp',\n",
    "            'fulfillment_labor_materials',\n",
    "            'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
    "            'total_price_excluding_optional_support',\n",
    "            'total_price_including_optional_support',\n",
    "            'students_reached',\n",
    "            'high poverty', 'highest poverty', 'low poverty','moderate poverty', \n",
    "            'Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Applied Learning',\n",
    "            'Health & Sports', 'History & Civics', 'Literacy & Language',\n",
    "            'Math & Science', 'Music & The Arts', 'Special Needs']\n",
    "target = TARGET_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #discretize\n",
    "# for var in TO_BE_DISCRETIZED_VARIABLES:\n",
    "#     labeled_df = cf.discretize(labeled_df, var, 10, want_quantile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_df = labeled_df[features + target + DATE_VARIABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove outliers before \n",
    "for var in ['total_price_excluding_optional_support','total_price_including_optional_support','students_reached']:\n",
    "    labeled_df = cf.zscore_remove_outlier(labeled_df, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in labeled_df.columns:\n",
    "    print(col, type(labeled_df[col][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.has_na(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_df = cf.drop_missing(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_temporal_split_dfs(df, features, target_var, num):\n",
    "    '''\n",
    "    features = list of features\n",
    "    target = target variable\n",
    "    num = refers to the dictionary keys of temporal_splits_dict\n",
    "    '''\n",
    "    \n",
    "    temporal_splits_dict = {1:(('2011-01-01', '2011-12-31'),('2012-01-01', '2012-06-31')),\n",
    "                        2:(('2011-01-01', '2012-06-31'),('2012-07-01', '2012-12-31')),\n",
    "                        3:(('2011-01-01', '2012-12-31'),('2013-01-01', '2013-06-31')),\n",
    "                        4:(('2011-01-01', '2013-06-31'),('2013-07-01', '2013-12-31'))}\n",
    "    \n",
    "    train_date_range = temporal_splits_dict[num][0]\n",
    "    x_train = df[features + ['date_posted']]\n",
    "    x_train = ld.limit_date_range(x_train, train_date_range, 'date_posted')\n",
    "    print('x_train min:', min(x_train.date_posted),', x_train max: ', max(x_train.date_posted))\n",
    "    x_train = x_train.drop('date_posted', axis=1)\n",
    "    \n",
    "    y_train = df[target_var + ['date_posted']]\n",
    "    y_train = ld.limit_date_range(y_train, train_date_range, 'date_posted')\n",
    "    print('y_train min:', min(y_train.date_posted),', y_train max: ', max(y_train.date_posted))\n",
    "    y_train = y_train.drop('date_posted', axis=1)\n",
    "\n",
    "    test_date_range = temporal_splits_dict[num][1]\n",
    "    x_test = df[features + ['date_posted']]\n",
    "    x_test = ld.limit_date_range(x_test, test_date_range, 'date_posted')\n",
    "    print('x_test min:', min(x_test.date_posted),', x_test max: ', max(x_test.date_posted))\n",
    "    x_test = x_test.drop('date_posted', axis=1)\n",
    "    \n",
    "    y_test = df[target_var + ['date_posted']]\n",
    "    y_test = ld.limit_date_range(y_test, test_date_range, 'date_posted')\n",
    "    print('y_test min:', min(y_test.date_posted),', y_test max: ', max(y_test.date_posted))\n",
    "    y_test = y_test.drop('date_posted', axis=1)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adapted from: https://github.com/rayidghani/magicloops/blob/master/simpleloop.py\n",
    "\n",
    "\n",
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "            'BAGGING': BaggingClassifier()\n",
    "           }\n",
    "\n",
    "    large_grid = { \n",
    "    'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']},\n",
    "        'BAGGING':{}\n",
    "           }\n",
    "    \n",
    "    small_grid = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.001,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           ,'BAGGING':{}}\n",
    "    \n",
    "    test_grid = { \n",
    "    'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'LR': { 'penalty': ['l1'], 'C': [0.01]},\n",
    "    'SGD': { 'loss': ['perceptron'], 'penalty': ['l2']},\n",
    "    'ET': { 'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5],'weights': ['uniform'],'algorithm': ['auto']}\n",
    "           ,'BAGGING':{}}\n",
    "    \n",
    "    if (grid_size == 'large'):\n",
    "        return clfs, large_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "# a set of helper function to do machine learning evalaution\n",
    "\n",
    "def joint_sort_descending(l1, l2):\n",
    "    # l1 and l2 have to be numpy arrays\n",
    "    idx = np.argsort(l1)[::-1]\n",
    "    return l1[idx], l2[idx]\n",
    "\n",
    "def generate_binary_at_k(y_scores, k):\n",
    "    cutoff_index = int(len(y_scores) * (k / 100.0))\n",
    "    test_predictions_binary = [1 if x < cutoff_index else 0 for x in range(len(y_scores))]\n",
    "    return test_predictions_binary\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    y_scores, y_true = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores, k)\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "    precision = precision_score(y_true, preds_at_k)\n",
    "    return precision\n",
    "\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax2.set_xlim([0,1])\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()\n",
    "    \n",
    "def recall_at_k(y_true, y_scores, k):\n",
    "    '''\n",
    "    From Rayid's mlfunctions.py: https://github.com/rayidghani/magicloops/blob/master/mlfunctions.py\n",
    "    '''\n",
    "    #y_scores_sorted, y_true_sorted = zip(*sorted(zip(y_scores, y_true), reverse=True))\n",
    "    y_scores_sorted, y_true_sorted = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores_sorted, k)\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "    recall = recall_score(y_true_sorted, preds_at_k)\n",
    "    return recall\n",
    "\n",
    "def get_subsets(l):\n",
    "    '''    \n",
    "    From Rayid's mlfunctions.py: https://github.com/rayidghani/magicloops/blob/master/mlfunctions.py\n",
    "    '''\n",
    "    subsets = []\n",
    "    for i in range(1, len(l) + 1):\n",
    "        for combo in itertools.combinations(l, i):\n",
    "            subsets.append(list(combo))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('model_type','clf', 'parameters', 'auc-roc', 'baseline'))\n",
    "#                                         ,'p_at_5', 'p_at_10', 'p_at_20'))\n",
    "    for n in range(1, 2):\n",
    "        # create training and valdation sets\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "#                     y_pred_probs = clf.fit(X_train, y_train.values.ravel()).predict_proba(X_test)[:,1]\n",
    "                    y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_test), reverse=True))\n",
    "                    results_df.loc[len(results_df)] = [models_to_run[index],clf, p,\n",
    "                                                       roc_auc_score(y_test, y_pred_probs),\n",
    "                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,100.0)]\n",
    "#                                                        ,precision_at_k(y_test_sorted,y_pred_probs_sorted,5.0),\n",
    "#                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,10.0),\n",
    "#                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,20.0)]\n",
    "                    #plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:',e)\n",
    "                    continue\n",
    "    return results_df\n",
    "\n",
    " \n",
    "def go_function(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # define grid to use: test, small, large\n",
    "    grid_size = 'test'\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "\n",
    "    # define models to run\n",
    "    models_to_run=['RF','DT','KNN', 'AB', 'LR', 'NB', 'BAGGING']\n",
    "\n",
    "\n",
    "    # call clf_loop and store results in results_df\n",
    "    results_df = clf_loop(models_to_run, clfs,grid, X_train, X_test, y_train, y_test)\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = create_temporal_split_dfs(labeled_df, features, target, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_function(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
