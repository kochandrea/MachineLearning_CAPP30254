{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from Rayid Ghani's simple loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LoadData import outcomes_df, projects_df, donors_choose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import CleaningFunctions as cf\n",
    "import ExplorationFunctions as ef\n",
    "import LoadData as ld\n",
    "from Variables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akoko0530/Documents/GitHub/MachineLearning_CAPP30254/Homework_3/CleaningFunctions.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = df[col].apply(lambda x: 1 if x=='t' else 0)\n",
      "/Users/akoko0530/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/akoko0530/Documents/GitHub/MachineLearning_CAPP30254/Homework_3/CleaningFunctions.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[column_name] = pd.qcut(df[column_name], q=num_bins, labels=bin_array)\n"
     ]
    }
   ],
   "source": [
    "remove_from_projects = GEO_VARIABLES + ID_VARIABLES + IDX\n",
    "keep_vars = [x for x in projects_df.columns if x not in remove_from_projects]\n",
    "labeled_df = donors_choose_df[keep_vars + TARGET_VARIABLES]\n",
    "labeled_df = cf.change_to_1_0(labeled_df)\n",
    "labeled_df = cf.impute_mean(labeled_df, given_cols=CONTINUOUS_VARIABLES)\n",
    "for var in CONTINUOUS_VARIABLES:\n",
    "    labeled_df = cf.discretize(labeled_df, var, 10, want_quantile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_list = list(projects_df.columns)\n",
    "# p_list = p_list[6:] #remove columns dealing with IDs and latlong\n",
    "# keep_cols = list(p_list) + ['fully_funded']\n",
    "# labeled_df = donors_choose_df[keep_cols] #dataframe of projects info with funding info\n",
    "# labeled_df = cf.dummytize(labeled_df)\n",
    "# labeled_df = cf.impute_mean(labeled_df, given_cols=DISCRETE_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_city', 'school_state', 'school_zip', 'school_metro',\n",
       "       'school_district', 'school_county', 'school_charter', 'school_magnet',\n",
       "       'school_year_round', 'school_nlns', 'school_kipp',\n",
       "       'school_charter_ready_promise', 'teacher_prefix',\n",
       "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
       "       'primary_focus_subject', 'primary_focus_area',\n",
       "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
       "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
       "       'total_price_excluding_optional_support',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
       "       'date_posted', 'fully_funded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dum_variables_of_interest = [\n",
    "'poverty_level', \n",
    "'teacher_prefix',\n",
    "'primary_focus_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = cf.dummytize(labeled_df, dum_variables_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school_city', 'school_state', 'school_zip', 'school_metro',\n",
       "       'school_district', 'school_county', 'school_charter', 'school_magnet',\n",
       "       'school_year_round', 'school_nlns', 'school_kipp',\n",
       "       'school_charter_ready_promise', 'teacher_prefix',\n",
       "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
       "       'primary_focus_subject', 'primary_focus_area',\n",
       "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
       "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
       "       'total_price_excluding_optional_support',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
       "       'date_posted', 'fully_funded', 'high poverty', 'highest poverty',\n",
       "       'low poverty', 'moderate poverty', 'Dr.', 'Mr.', 'Mrs.', 'Ms.',\n",
       "       'Applied Learning', 'Health & Sports', 'History & Civics',\n",
       "       'Literacy & Language', 'Math & Science', 'Music & The Arts',\n",
       "       'Special Needs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = ['school_nlns', 'school_kipp',\n",
    "#             'fulfillment_labor_materials',\n",
    "#             'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
    "#             'total_price_excluding_optional_support',\n",
    "#             'total_price_including_optional_support',\n",
    "#             'students_reached',\n",
    "#             'high poverty', 'highest poverty', 'low poverty','moderate poverty', \n",
    "#             'Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Applied Learning',\n",
    "#             'Health & Sports', 'History & Civics', 'Literacy & Language',\n",
    "#             'Math & Science', 'Music & The Arts', 'Special Needs']\n",
    "target = TARGET_VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features =['Dr.', 'Mr.', 'Mrs.', 'Ms.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #discretize\n",
    "# for var in DISCRETE_VARIABLES:\n",
    "#     labeled_df = cf.discretize(labeled_df, var, 10, want_quantile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_df = labeled_df[features + target + DATE_VARIABLE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dr.', 'Mr.', 'Mrs.', 'Ms.', 'fully_funded', 'date_posted'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353151, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #remove outliers before \n",
    "# for var in ['total_price_excluding_optional_support','total_price_including_optional_support','students_reached']:\n",
    "#     labeled_df = cf.zscore_remove_outlier(labeled_df, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353151, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. <class 'numpy.uint8'>\n",
      "Mr. <class 'numpy.uint8'>\n",
      "Mrs. <class 'numpy.uint8'>\n",
      "Ms. <class 'numpy.uint8'>\n",
      "fully_funded <class 'numpy.int64'>\n",
      "date_posted <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for col in labeled_df.columns:\n",
    "    print(col, type(labeled_df[col][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.has_na(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_df = cf.drop_missing(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353151, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dr.</th>\n",
       "      <th>Mr.</th>\n",
       "      <th>Mrs.</th>\n",
       "      <th>Ms.</th>\n",
       "      <th>fully_funded</th>\n",
       "      <th>date_posted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projectid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ffffac55ee02a49d1abc87ba6fc61135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff2d9c769c8fb5335e949c615425eb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffeebf4827d745aa36b17c2d38d1966</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffeaae9482c9b72cab5bbd3f061d362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffe45b28ea6f2889de1e3f797fb31a3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Dr.  Mr.  Mrs.  Ms.  fully_funded  \\\n",
       "projectid                                                             \n",
       "ffffac55ee02a49d1abc87ba6fc61135    0    0     0    1             1   \n",
       "ffff2d9c769c8fb5335e949c615425eb    0    0     1    0             1   \n",
       "fffeebf4827d745aa36b17c2d38d1966    0    1     0    0             1   \n",
       "fffeaae9482c9b72cab5bbd3f061d362    0    0     1    0             0   \n",
       "fffe45b28ea6f2889de1e3f797fb31a3    0    0     1    0             1   \n",
       "\n",
       "                                 date_posted  \n",
       "projectid                                     \n",
       "ffffac55ee02a49d1abc87ba6fc61135  2011-06-11  \n",
       "ffff2d9c769c8fb5335e949c615425eb  2013-03-03  \n",
       "fffeebf4827d745aa36b17c2d38d1966  2012-12-01  \n",
       "fffeaae9482c9b72cab5bbd3f061d362  2011-07-26  \n",
       "fffe45b28ea6f2889de1e3f797fb31a3  2012-01-14  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akoko0530/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/akoko0530/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_temporal_split_dfs(df, features, target_var, num):\n",
    "    '''\n",
    "    features = list of features\n",
    "    target = target variable\n",
    "    num = refers to the dictionary keys of temporal_splits_dict\n",
    "    ##With more time, would implement using datetime module\n",
    "    '''\n",
    "    \n",
    "    temporal_splits_dict = {1:(('2011-01-01', '2011-12-31'),('2012-01-01', '2012-06-31')),\n",
    "                        2:(('2011-01-01', '2012-06-31'),('2012-07-01', '2012-12-31')),\n",
    "                        3:(('2011-01-01', '2012-12-31'),('2013-01-01', '2013-06-31')),\n",
    "                        4:(('2011-01-01', '2013-06-31'),('2013-07-01', '2013-12-31'))}\n",
    "    \n",
    "    train_date_range = temporal_splits_dict[num][0]\n",
    "    x_train = df[features + ['date_posted']]\n",
    "    x_train = ld.limit_date_range(x_train, train_date_range, 'date_posted')\n",
    "    print('x_train min:', min(x_train.date_posted),', x_train max: ', max(x_train.date_posted))\n",
    "    x_train = x_train.drop('date_posted', axis=1)\n",
    "    \n",
    "    y_train = df[target_var + ['date_posted']]\n",
    "    y_train = ld.limit_date_range(y_train, train_date_range, 'date_posted')\n",
    "    print('y_train min:', min(y_train.date_posted),', y_train max: ', max(y_train.date_posted))\n",
    "    y_train = y_train.drop('date_posted', axis=1)\n",
    "\n",
    "    test_date_range = temporal_splits_dict[num][1]\n",
    "    x_test = df[features + ['date_posted']]\n",
    "    x_test = ld.limit_date_range(x_test, test_date_range, 'date_posted')\n",
    "    print('x_test min:', min(x_test.date_posted),', x_test max: ', max(x_test.date_posted))\n",
    "    x_test = x_test.drop('date_posted', axis=1)\n",
    "    \n",
    "    y_test = df[target_var + ['date_posted']]\n",
    "    y_test = ld.limit_date_range(y_test, test_date_range, 'date_posted')\n",
    "    print('y_test min:', min(y_test.date_posted),', y_test max: ', max(y_test.date_posted))\n",
    "    y_test = y_test.drop('date_posted', axis=1)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adapted from: https://github.com/rayidghani/magicloops/blob/master/simpleloop.py\n",
    "\n",
    "\n",
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3),\n",
    "            'BAGGING': BaggingClassifier()\n",
    "           }\n",
    "\n",
    "    large_grid = { \n",
    "    'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']},\n",
    "        'BAGGING':{}\n",
    "           }\n",
    "    \n",
    "    small_grid = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.001,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           ,'BAGGING':{}}\n",
    "    \n",
    "    test_grid = { \n",
    "    'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'LR': { 'penalty': ['l1'], 'C': [0.01]},\n",
    "    'SGD': { 'loss': ['perceptron'], 'penalty': ['l2']},\n",
    "    'ET': { 'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5],'weights': ['uniform'],'algorithm': ['auto']}\n",
    "           ,'BAGGING':{}}\n",
    "    \n",
    "    if (grid_size == 'large'):\n",
    "        return clfs, large_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "# a set of helper function to do machine learning evalaution\n",
    "\n",
    "def joint_sort_descending(l1, l2):\n",
    "    # l1 and l2 have to be numpy arrays\n",
    "    idx = np.argsort(l1)[::-1]\n",
    "    return l1[idx], l2[idx]\n",
    "\n",
    "def generate_binary_at_k(y_scores, k):\n",
    "    cutoff_index = int(len(y_scores) * (k / 100.0))\n",
    "    test_predictions_binary = [1 if x < cutoff_index else 0 for x in range(len(y_scores))]\n",
    "    return test_predictions_binary\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    y_scores, y_true = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = np.asarray(generate_binary_at_k(y_scores, k))\n",
    "    print('y_scores ', y_scores)\n",
    "    print(type(y_scores))    \n",
    "    print('PREDS_AT_K: ', preds_at_k)\n",
    "    print(type(preds_at_k))\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "#     precision = precision_score(y_true, np.asarray(preds_at_k))\n",
    "    precision = precision_score(y_true, preds_at_k, labels=None)\n",
    "    return precision\n",
    "\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax1.set_ylim([0,1])\n",
    "    ax2.set_xlim([0,1])\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()\n",
    "    \n",
    "def recall_at_k(y_true, y_scores, k):\n",
    "    '''\n",
    "    From Rayid's mlfunctions.py: https://github.com/rayidghani/magicloops/blob/master/mlfunctions.py\n",
    "    '''\n",
    "    #y_scores_sorted, y_true_sorted = zip(*sorted(zip(y_scores, y_true), reverse=True))\n",
    "    y_scores_sorted, y_true_sorted = joint_sort_descending(np.array(y_scores), np.array(y_true))\n",
    "    preds_at_k = generate_binary_at_k(y_scores_sorted, k)\n",
    "    #precision, _, _, _ = metrics.precision_recall_fscore_support(y_true, preds_at_k)\n",
    "    #precision = precision[1]  # only interested in precision for label 1\n",
    "    recall = recall_score(y_true_sorted, preds_at_k)\n",
    "    return recall\n",
    "\n",
    "def get_subsets(l):\n",
    "    '''    \n",
    "    From Rayid's mlfunctions.py: https://github.com/rayidghani/magicloops/blob/master/mlfunctions.py\n",
    "    '''\n",
    "    subsets = []\n",
    "    for i in range(1, len(l) + 1):\n",
    "        for combo in itertools.combinations(l, i):\n",
    "            subsets.append(list(combo))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clf_loop(models_to_run, clfs, grid, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Runs the loop using models_to_run, clfs, gridm and the data\n",
    "    \"\"\"\n",
    "    results_df =  pd.DataFrame(columns=('model_type','clf', 'parameters', 'auc-roc'\n",
    "                                        , 'baseline'))\n",
    "#                                         ,'p_at_5', 'p_at_10', 'p_at_20'))\n",
    "    for n in range(1, 2):\n",
    "        # create training and valdation sets\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    y_pred_probs = clf.fit(X_train, y_train.values.ravel()).predict_proba(X_test)[:,1]\n",
    "#                     y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    # you can also store the model, feature importances, and prediction scores\n",
    "                    # we're only storing the metrics for now\n",
    "                    y_pred_probs_sorted, y_test_sorted = zip(*sorted(zip(y_pred_probs, y_test), reverse=True))\n",
    "                    y_pred_probs_sorted = np.asarray(y_pred_probs_sorted)\n",
    "                    print(\"Y_pred_probs:\", y_pred_probs)\n",
    "                    print(type(y_pred_probs), '\\n')\n",
    "                    print(\"y_pred_probs_sorted:\", y_pred_probs_sorted)\n",
    "                    print(type(y_pred_probs_sorted), '\\n')\n",
    "                    results_df.loc[len(results_df)] = [models_to_run[index],clf, p,\n",
    "                                                       roc_auc_score(y_test, y_pred_probs)\n",
    "                                                        ,precision_at_k(y_test_sorted,y_pred_probs_sorted,100.0)]\n",
    "#                                                        ,precision_at_k(y_test_sorted,y_pred_probs_sorted,5.0),\n",
    "#                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,10.0),\n",
    "#                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,20.0)]\n",
    "                    #plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                except IndexError as e:\n",
    "                    print('Error:',e)\n",
    "                    continue\n",
    "    return results_df\n",
    "\n",
    " \n",
    "def go_function(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # define grid to use: test, small, large\n",
    "    grid_size = 'test'\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "\n",
    "    # define models to run\n",
    "    models_to_run=['RF','DT','KNN', 'AB', 'LR', 'NB', 'BAGGING']\n",
    "\n",
    "\n",
    "    # call clf_loop and store results in results_df\n",
    "    results_df = clf_loop(models_to_run, clfs,grid, X_train, X_test, y_train, y_test)\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train min: 2011-01-01 , x_train max:  2012-06-30\n",
      "y_train min: 2011-01-01 , y_train max:  2012-06-30\n",
      "x_test min: 2012-07-01 , x_test max:  2012-12-31\n",
      "y_test min: 2012-07-01 , y_test max:  2012-12-31\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = create_temporal_split_dfs(labeled_df, features, target, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "[0 1] \n",
      "\n",
      "Mr.\n",
      "[0 1] \n",
      "\n",
      "Mrs.\n",
      "[0 1] \n",
      "\n",
      "Ms.\n",
      "[1 0] \n",
      "\n",
      "Dr.\n",
      "[0 1] \n",
      "\n",
      "Mr.\n",
      "[0 1] \n",
      "\n",
      "Mrs.\n",
      "[0 1] \n",
      "\n",
      "Ms.\n",
      "[1 0] \n",
      "\n",
      "fully_funded\n",
      "[1 0] \n",
      "\n",
      "fully_funded\n",
      "[1 0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in [X_train, X_test, y_train, y_test]:\n",
    "    for col in df.columns:\n",
    "        print(col)\n",
    "        print(labeled_df[col].unique(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "Y_pred_probs: [0.67067427 0.67067427 0.67067427 ... 0.67067427 0.70579017 0.70579017]\n",
      "<class 'numpy.ndarray'> \n",
      "\n",
      "y_pred_probs_sorted: [0.67067427]\n",
      "<class 'numpy.ndarray'> \n",
      "\n",
      "y_scores  [0.67067427]\n",
      "<class 'numpy.ndarray'>\n",
      "PREDS_AT_K:  [1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f1798daa1ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgo_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-5cc049bc196a>\u001b[0m in \u001b[0;36mgo_function\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# call clf_loop and store results in results_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5cc049bc196a>\u001b[0m in \u001b[0;36mclf_loop\u001b[0;34m(models_to_run, clfs, grid, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     results_df.loc[len(results_df)] = [models_to_run[index],clf, p,\n\u001b[1;32m     27\u001b[0m                                                        \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                         ,precision_at_k(y_test_sorted,y_pred_probs_sorted,100.0)]\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#                                                        ,precision_at_k(y_test_sorted,y_pred_probs_sorted,5.0),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#                                                        precision_at_k(y_test_sorted,y_pred_probs_sorted,10.0),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-b79015d88cc5>\u001b[0m in \u001b[0;36mprecision_at_k\u001b[0;34m(y_true, y_scores, k)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m#precision = precision[1]  # only interested in precision for label 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#     precision = precision_score(y_true, np.asarray(preds_at_k))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_at_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1259\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "go_function(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
